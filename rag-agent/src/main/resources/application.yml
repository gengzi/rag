server:
  port: 8889


spring:
  ai:
    chat:
      client:
        enabled: false

    openai:
      api-key: test

## 自定义对话模型参数配置
chatmodel:
  apiKey: sk-ltrjtwcekfkowwmdqghjzgfkjhylcocxibuuviorbnfzvqqj
  baseUrl: https://api.siliconflow.cn
  model: deepseek-ai/DeepSeek-V3
  ## 由于构建rag程序，设置模型的温度低一点。较高的值（例如 0.8）会使输出更具随机性，而较低的值（例如 0.2）会使输出更具针对性和确定性
  temperature: 0.3
